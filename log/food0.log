2024-12-07 21:51:41,845 - main - INFO - Start running with args: 
Namespace(batch_size=128, distillw=0.5, enable_smoothing=False, enable_mixup=False, w_dis_token=False, img_size=224, prototype_shape=[510, 768, 1, 1], prototype_activation_function='log', add_on_layers_type='regular', baseline_path=None, use_global=True, global_proto_per_class=10, features_lr=0.0001, add_on_layers_lr=0.001, prototype_vectors_lr=0.001, joint_lr_step_size=5, coefs_crs_ent=1, coefs_clst=0.8, coefs_sep=-0.08, coefs_l1=0.0001, epochs=200, save_ep_freq=400, drop=0.0, drop_path=0.1, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=0.0001, min_lr=1e-05, decay_epochs=10.0, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.0, train_interpolation='bicubic', reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', prop_train_labels=0.5, mask_theta=0.1, labeled_nums=51, data_set='CD_food', inat_category='name', output_dir='output_cosine//CD_food/food_iscap_seed(1027)', device='cuda', seed=1027, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=10, pin_mem=True, world_size=1, dist_url='env://', hash_code_length=12, prototype_dim=768, data_root='/leonardo_work/IscrC_Fed-GCD/GCD_datasets', pretrain_path='/leonardo_work/IscrC_Fed-GCD/GCD_datasets/dino/dino_vitbase16_pretrain.pth', distributed=False)
2024-12-07 21:51:41,845 - main - INFO - Distributed: False
/leonardo/home/userexternal/hzheng00/miniconda3/envs/fedgcd/lib/python3.9/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2024-12-07 21:51:47,349 - main - INFO - Dataset num_classes: 51
2024-12-07 21:51:47,350 - main - INFO - train 19125 test: 12750
2024-12-07 21:51:47,350 - main - INFO - test_dataset_unlabelled: 56625
/leonardo/home/userexternal/hzheng00/miniconda3/envs/fedgcd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/leonardo/home/userexternal/hzheng00/miniconda3/envs/fedgcd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2024-12-07 21:51:47,352 - main - INFO - Label smoothing is not enabled, smoothing rate: 0.0
2024-12-07 21:51:47,352 - main - INFO - Mixup is not enabled
2024-12-07 21:51:51,296 - main - INFO - number of params: 14369560
2024-12-07 21:51:51,297 - main - INFO - Start training for 200 epochs
2024-12-07 21:51:51,297 - train_one_epoch - INFO - Start train one epoch
Not using distributed mode
len(dataset_train) 19125
require grad: prototype_vectors_global
require grad: features.blocks.11.norm1.weight
require grad: features.blocks.11.norm1.bias
require grad: features.blocks.11.attn.qkv.weight
require grad: features.blocks.11.attn.qkv.bias
require grad: features.blocks.11.attn.proj.weight
require grad: features.blocks.11.attn.proj.bias
require grad: features.blocks.11.norm2.weight
require grad: features.blocks.11.norm2.bias
require grad: features.blocks.11.mlp.fc1.weight
require grad: features.blocks.11.mlp.fc1.bias
require grad: features.blocks.11.mlp.fc2.weight
require grad: features.blocks.11.mlp.fc2.bias
require grad: add_on_layers.0.weight
require grad: add_on_layers.0.bias
require grad: hash_head.mlp.0.weight
require grad: hash_head.mlp.0.bias
require grad: hash_head.mlp.2.weight
require grad: hash_head.mlp.2.bias
require grad: hash_head.mlp.4.weight
require grad: hash_head.mlp.4.bias
require grad: hash_head.mlp.5.weight
require grad: hash_head.mlp.5.bias
require grad: hash_head.hash.weight
require grad: hash_head.bn_h.weight
require grad: hash_head.bn_h.bias
Param Group 0:
Parameters:
torch.Size([768])
torch.Size([768])
torch.Size([2304, 768])
torch.Size([2304])
torch.Size([768, 768])
torch.Size([768])
torch.Size([768])
torch.Size([768])
torch.Size([3072, 768])
torch.Size([3072])
torch.Size([768, 3072])
torch.Size([768])
Config:
lr: 0.0001
weight_decay: 0.001
betas: (0.9, 0.999)
eps: 1e-08
amsgrad: False
foreach: None
maximize: False
capturable: False


Param Group 1:
Parameters:
torch.Size([768, 768])
torch.Size([768])
Config:
lr: 0.001
weight_decay: 0.001
betas: (0.9, 0.999)
eps: 1e-08
amsgrad: False
foreach: None
maximize: False
capturable: False


Param Group 2:
Parameters:
torch.Size([2048, 768])
torch.Size([2048])
torch.Size([2048, 2048])
torch.Size([2048])
torch.Size([256, 2048])
torch.Size([256])
torch.Size([256])
torch.Size([256])
torch.Size([12, 256])
torch.Size([12])
torch.Size([12])
Config:
lr: 0.001
betas: (0.9, 0.999)
eps: 1e-08
weight_decay: 0.05
amsgrad: False
foreach: None
maximize: False
capturable: False


Param Group 3:
Parameters:
torch.Size([510, 768])
Config:
lr: 0.001
betas: (0.9, 0.999)
eps: 1e-08
weight_decay: 0.05
amsgrad: False
foreach: None
maximize: False
capturable: False


/leonardo_work/IscrC_Fed-GCD/hyzheng/PHE_release/train_eval.py:31: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  labels = torch.arange(protop_centers.shape[0]) // samples_per_class
2024-12-07 21:52:18,024 - log_every - INFO - Epoch: [0]  [  0/150]  eta: 1:06:48  lr: 0.000100  loss_protop: 4.3081 (4.3081)  loss_feature: 3.9621 (3.9621)  loss_sep: 0.0000 (0.0000)  loss_quan: 0.5996 (0.5996)  time: 26.7231  data: 17.8656  max mem: 2686
2024-12-07 21:52:29,143 - log_every - INFO - Epoch: [0]  [ 30/150]  eta: 0:02:26  lr: 0.000100  loss_protop: 4.2636 (4.2645)  loss_feature: 3.3818 (3.5085)  loss_sep: 0.0385 (0.0352)  loss_quan: 0.3174 (0.3689)  time: 0.4634  data: 0.2098  max mem: 2851
2024-12-07 21:52:56,658 - log_every - INFO - Epoch: [0]  [ 60/150]  eta: 0:01:36  lr: 0.000100  loss_protop: 4.2359 (4.2569)  loss_feature: 3.2763 (3.3982)  loss_sep: 0.0089 (0.0236)  loss_quan: 0.2852 (0.3288)  time: 0.9092  data: 0.6322  max mem: 2851
2024-12-07 21:53:23,785 - log_every - INFO - Epoch: [0]  [ 90/150]  eta: 0:01:00  lr: 0.000100  loss_protop: 4.1927 (4.2410)  loss_feature: 3.2242 (3.3440)  loss_sep: 0.0089 (0.0186)  loss_quan: 0.2786 (0.3128)  time: 0.9089  data: 0.6280  max mem: 2851
2024-12-07 21:53:51,029 - log_every - INFO - Epoch: [0]  [120/150]  eta: 0:00:29  lr: 0.000100  loss_protop: 4.1996 (4.2273)  loss_feature: 3.2141 (3.3122)  loss_sep: 0.0041 (0.0158)  loss_quan: 0.2754 (0.3040)  time: 0.9075  data: 0.6491  max mem: 2851
2024-12-07 21:54:15,279 - log_every - INFO - Epoch: [0]  [149/150]  eta: 0:00:00  lr: 0.000100  loss_protop: 4.1812 (4.2181)  loss_feature: 3.2073 (3.2918)  loss_sep: 0.0060 (0.0141)  loss_quan: 0.2664 (0.2973)  time: 0.7594  data: 0.5520  max mem: 2851
2024-12-07 21:54:15,482 - log_every - INFO - Epoch: [0] Total time: 0:02:24 (0.9612 s / it)
2024-12-07 21:54:15,486 - evaluate - INFO - Start validation
Averaged stats: lr: 0.000100  loss_protop: 4.1812 (4.2181)  loss_feature: 3.2073 (3.2918)  loss_sep: 0.0060 (0.0141)  loss_quan: 0.2664 (0.2973)
  0%|          | 0/222 [00:00<?, ?it/s]  0%|          | 1/222 [00:15<55:43, 15.13s/it]  1%|          | 2/222 [00:15<24:39,  6.72s/it]  1%|▏         | 3/222 [00:16<14:39,  4.02s/it]  2%|▏         | 4/222 [00:17<10:08,  2.79s/it]  2%|▏         | 5/222 [00:18<07:37,  2.11s/it]  3%|▎         | 6/222 [00:19<06:06,  1.70s/it]  3%|▎         | 7/222 [00:20<05:07,  1.43s/it]  4%|▎         | 8/222 [00:21<04:30,  1.26s/it]  4%|▍         | 9/222 [00:29<11:59,  3.38s/it]  5%|▍         | 10/222 [00:30<09:15,  2.62s/it]  5%|▍         | 11/222 [00:31<07:18,  2.08s/it]  5%|▌         | 12/222 [00:31<05:59,  1.71s/it]  6%|▌         | 13/222 [00:32<05:13,  1.50s/it]  6%|▋         | 14/222 [00:33<04:29,  1.30s/it]  7%|▋         | 15/222 [00:34<03:56,  1.14s/it]  7%|▋         | 16/222 [00:35<03:38,  1.06s/it]  8%|▊         | 17/222 [00:42<10:05,  2.96s/it]  8%|▊         | 18/222 [00:43<07:54,  2.33s/it]  9%|▊         | 19/222 [00:44<06:27,  1.91s/it]  9%|▉         | 20/222 [00:45<05:20,  1.59s/it]  9%|▉         | 21/222 [00:46<04:33,  1.36s/it] 10%|▉         | 22/222 [00:47<04:02,  1.21s/it] 10%|█         | 23/222 [00:48<03:44,  1.13s/it] 11%|█         | 24/222 [00:48<03:27,  1.05s/it] 11%|█▏        | 25/222 [00:57<10:46,  3.28s/it] 12%|█▏        | 26/222 [00:58<08:21,  2.56s/it] 12%|█▏        | 27/222 [00:59<06:44,  2.08s/it] 13%|█▎        | 28/222 [01:00<05:33,  1.72s/it] 13%|█▎        | 29/222 [01:00<04:43,  1.47s/it] 14%|█▎        | 30/222 [01:01<04:09,  1.30s/it] 14%|█▍        | 31/222 [01:02<03:47,  1.19s/it] 14%|█▍        | 32/222 [01:03<03:27,  1.09s/it] 15%|█▍        | 33/222 [01:11<09:41,  3.08s/it] 15%|█▌        | 34/222 [01:12<07:33,  2.41s/it] 16%|█▌        | 35/222 [01:13<06:08,  1.97s/it] 16%|█▌        | 36/222 [01:14<05:04,  1.64s/it] 17%|█▋        | 37/222 [01:14<04:20,  1.41s/it] 17%|█▋        | 38/222 [01:15<03:52,  1.26s/it] 18%|█▊        | 39/222 [01:16<03:30,  1.15s/it] 18%|█▊        | 40/222 [01:17<03:15,  1.07s/it] 18%|█▊        | 41/222 [01:25<09:19,  3.09s/it] 19%|█▉        | 42/222 [01:26<07:18,  2.43s/it] 19%|█▉        | 43/222 [01:27<05:46,  1.94s/it] 20%|█▉        | 44/222 [01:28<04:48,  1.62s/it] 20%|██        | 45/222 [01:28<04:07,  1.40s/it] 21%|██        | 46/222 [01:29<03:37,  1.24s/it] 21%|██        | 47/222 [01:30<03:18,  1.13s/it] 22%|██▏       | 48/222 [01:31<03:01,  1.04s/it] 22%|██▏       | 49/222 [01:39<09:18,  3.23s/it] 23%|██▎       | 50/222 [01:40<07:13,  2.52s/it] 23%|██▎       | 51/222 [01:41<05:43,  2.01s/it] 23%|██▎       | 52/222 [01:42<04:42,  1.66s/it] 24%|██▍       | 53/222 [01:43<03:56,  1.40s/it] 24%|██▍       | 54/222 [01:44<03:33,  1.27s/it] 25%|██▍       | 55/222 [01:45<03:18,  1.19s/it] 25%|██▌       | 56/222 [01:45<02:56,  1.06s/it] 26%|██▌       | 57/222 [01:53<08:29,  3.09s/it] 26%|██▌       | 58/222 [01:54<06:38,  2.43s/it] 27%|██▋       | 59/222 [01:55<05:18,  1.96s/it] 27%|██▋       | 60/222 [01:56<04:24,  1.63s/it] 27%|██▋       | 61/222 [01:57<03:46,  1.41s/it] 28%|██▊       | 62/222 [01:58<03:19,  1.25s/it] 28%|██▊       | 63/222 [01:58<03:01,  1.14s/it] 29%|██▉       | 64/222 [01:59<02:45,  1.05s/it] 29%|██▉       | 65/222 [02:07<08:11,  3.13s/it] 30%|██▉       | 66/222 [02:08<06:22,  2.45s/it] 30%|███       | 67/222 [02:09<05:05,  1.97s/it] 31%|███       | 68/222 [02:10<04:11,  1.63s/it] 31%|███       | 69/222 [02:11<03:36,  1.41s/it] 32%|███▏      | 70/222 [02:12<03:08,  1.24s/it] 32%|███▏      | 71/222 [02:12<02:50,  1.13s/it] 32%|███▏      | 72/222 [02:13<02:38,  1.06s/it] 33%|███▎      | 73/222 [02:21<07:50,  3.16s/it] 33%|███▎      | 74/222 [02:22<06:06,  2.47s/it] 34%|███▍      | 75/222 [02:23<04:53,  2.00s/it] 34%|███▍      | 76/222 [02:24<04:02,  1.66s/it] 35%|███▍      | 77/222 [02:25<03:29,  1.44s/it] 35%|███▌      | 78/222 [02:26<03:00,  1.26s/it] 36%|███▌      | 79/222 [02:27<02:42,  1.14s/it] 36%|███▌      | 80/222 [02:27<02:29,  1.05s/it] 36%|███▋      | 81/222 [02:36<07:27,  3.17s/it] 37%|███▋      | 82/222 [02:36<05:47,  2.48s/it] 37%|███▋      | 83/222 [02:37<04:38,  2.00s/it] 38%|███▊      | 84/222 [02:38<03:49,  1.66s/it] 38%|███▊      | 85/222 [02:39<03:14,  1.42s/it] 39%|███▊      | 86/222 [02:40<02:50,  1.25s/it] 39%|███▉      | 87/222 [02:41<02:34,  1.14s/it] 40%|███▉      | 88/222 [02:42<02:21,  1.06s/it] 40%|████      | 89/222 [02:49<06:47,  3.06s/it] 41%|████      | 90/222 [02:50<05:19,  2.42s/it] 41%|████      | 91/222 [02:51<04:15,  1.95s/it] 41%|████▏     | 92/222 [02:52<03:31,  1.62s/it] 42%|████▏     | 93/222 [02:53<03:01,  1.40s/it] 42%|████▏     | 94/222 [02:54<02:36,  1.22s/it] 43%|████▎     | 95/222 [02:55<02:19,  1.10s/it] 43%|████▎     | 96/222 [02:55<02:11,  1.04s/it] 44%|████▎     | 97/222 [03:03<06:25,  3.08s/it] 44%|████▍     | 98/222 [03:04<05:00,  2.42s/it] 45%|████▍     | 99/222 [03:05<04:02,  1.97s/it] 45%|████▌     | 100/222 [03:06<03:21,  1.65s/it] 45%|████▌     | 101/222 [03:07<02:51,  1.42s/it] 46%|████▌     | 102/222 [03:08<02:31,  1.27s/it] 46%|████▋     | 103/222 [03:09<02:16,  1.15s/it] 47%|████▋     | 104/222 [03:10<02:03,  1.05s/it] 47%|████▋     | 105/222 [03:17<06:02,  3.10s/it] 48%|████▊     | 106/222 [03:18<04:40,  2.42s/it] 48%|████▊     | 107/222 [03:19<03:41,  1.93s/it] 49%|████▊     | 108/222 [03:20<03:02,  1.60s/it] 49%|████▉     | 109/222 [03:21<02:35,  1.38s/it] 50%|████▉     | 110/222 [03:22<02:14,  1.20s/it] 50%|█████     | 111/222 [03:22<02:00,  1.09s/it] 50%|█████     | 112/222 [03:23<01:50,  1.01s/it] 51%|█████     | 113/222 [03:31<05:35,  3.08s/it] 51%|█████▏    | 114/222 [03:32<04:22,  2.43s/it] 52%|█████▏    | 115/222 [03:33<03:32,  1.98s/it] 52%|█████▏    | 116/222 [03:34<02:53,  1.64s/it] 53%|█████▎    | 117/222 [03:35<02:27,  1.41s/it] 53%|█████▎    | 118/222 [03:36<02:11,  1.26s/it] 54%|█████▎    | 119/222 [03:36<01:56,  1.13s/it] 54%|█████▍    | 120/222 [03:37<01:46,  1.04s/it] 55%|█████▍    | 121/222 [03:46<05:29,  3.26s/it] 55%|█████▍    | 122/222 [03:47<04:14,  2.55s/it] 55%|█████▌    | 123/222 [03:47<03:21,  2.04s/it] 56%|█████▌    | 124/222 [03:48<02:45,  1.69s/it] 56%|█████▋    | 125/222 [03:49<02:21,  1.46s/it] 57%|█████▋    | 126/222 [03:50<02:01,  1.27s/it] 57%|█████▋    | 127/222 [03:51<01:49,  1.15s/it] 58%|█████▊    | 128/222 [03:52<01:40,  1.07s/it] 58%|█████▊    | 129/222 [04:00<04:49,  3.11s/it] 59%|█████▊    | 130/222 [04:00<03:44,  2.44s/it] 59%|█████▉    | 131/222 [04:01<02:59,  1.97s/it] 59%|█████▉    | 132/222 [04:02<02:24,  1.60s/it] 60%|█████▉    | 133/222 [04:03<02:04,  1.40s/it] 60%|██████    | 134/222 [04:04<01:49,  1.25s/it] 61%|██████    | 135/222 [04:05<01:37,  1.12s/it] 61%|██████▏   | 136/222 [04:06<01:29,  1.04s/it] 62%|██████▏   | 137/222 [04:14<04:24,  3.12s/it] 62%|██████▏   | 138/222 [04:14<03:25,  2.45s/it] 63%|██████▎   | 139/222 [04:15<02:43,  1.97s/it] 63%|██████▎   | 140/222 [04:16<02:13,  1.63s/it] 64%|██████▎   | 141/222 [04:17<01:54,  1.41s/it] 64%|██████▍   | 142/222 [04:18<01:40,  1.25s/it] 64%|██████▍   | 143/222 [04:19<01:30,  1.15s/it] 65%|██████▍   | 144/222 [04:20<01:24,  1.09s/it] 65%|██████▌   | 145/222 [04:27<03:55,  3.06s/it] 66%|██████▌   | 146/222 [04:28<03:03,  2.41s/it] 66%|██████▌   | 147/222 [04:29<02:25,  1.95s/it] 67%|██████▋   | 148/222 [04:30<02:00,  1.62s/it] 67%|██████▋   | 149/222 [04:31<01:41,  1.39s/it] 68%|██████▊   | 150/222 [04:32<01:28,  1.23s/it] 68%|██████▊   | 151/222 [04:33<01:18,  1.11s/it] 68%|██████▊   | 152/222 [04:33<01:12,  1.03s/it] 69%|██████▉   | 153/222 [04:42<03:44,  3.25s/it] 69%|██████▉   | 154/222 [04:43<02:51,  2.52s/it] 70%|██████▉   | 155/222 [04:44<02:16,  2.03s/it] 70%|███████   | 156/222 [04:44<01:51,  1.70s/it] 71%|███████   | 157/222 [04:45<01:34,  1.45s/it] 71%|███████   | 158/222 [04:46<01:21,  1.27s/it] 72%|███████▏  | 159/222 [04:47<01:12,  1.15s/it] 72%|███████▏  | 160/222 [04:48<01:06,  1.07s/it] 73%|███████▎  | 161/222 [04:55<03:03,  3.01s/it] 73%|███████▎  | 162/222 [04:56<02:22,  2.38s/it] 73%|███████▎  | 163/222 [04:57<01:54,  1.94s/it] 74%|███████▍  | 164/222 [04:58<01:34,  1.63s/it] 74%|███████▍  | 165/222 [04:59<01:20,  1.41s/it] 75%|███████▍  | 166/222 [05:00<01:09,  1.25s/it] 75%|███████▌  | 167/222 [05:01<01:03,  1.16s/it] 76%|███████▌  | 168/222 [05:02<00:56,  1.05s/it] 76%|███████▌  | 169/222 [05:09<02:41,  3.04s/it] 77%|███████▋  | 170/222 [05:10<02:04,  2.39s/it] 77%|███████▋  | 171/222 [05:11<01:38,  1.94s/it] 77%|███████▋  | 172/222 [05:12<01:20,  1.61s/it] 78%|███████▊  | 173/222 [05:13<01:07,  1.39s/it] 78%|███████▊  | 174/222 [05:14<00:59,  1.24s/it] 79%|███████▉  | 175/222 [05:15<00:52,  1.12s/it] 79%|███████▉  | 176/222 [05:16<00:48,  1.06s/it] 80%|███████▉  | 177/222 [05:23<02:18,  3.09s/it] 80%|████████  | 178/222 [05:24<01:47,  2.43s/it] 81%|████████  | 179/222 [05:25<01:24,  1.97s/it] 81%|████████  | 180/222 [05:26<01:08,  1.63s/it] 82%|████████▏ | 181/222 [05:27<00:57,  1.41s/it] 82%|████████▏ | 182/222 [05:28<00:49,  1.24s/it] 82%|████████▏ | 183/222 [05:29<00:44,  1.13s/it] 83%|████████▎ | 184/222 [05:29<00:39,  1.05s/it] 83%|████████▎ | 185/222 [05:37<01:52,  3.05s/it] 84%|████████▍ | 186/222 [05:38<01:26,  2.39s/it] 84%|████████▍ | 187/222 [05:39<01:08,  1.95s/it] 85%|████████▍ | 188/222 [05:40<00:55,  1.63s/it] 85%|████████▌ | 189/222 [05:41<00:44,  1.35s/it] 86%|████████▌ | 190/222 [05:41<00:38,  1.20s/it] 86%|████████▌ | 191/222 [05:42<00:33,  1.09s/it] 86%|████████▋ | 192/222 [05:43<00:31,  1.03s/it] 87%|████████▋ | 193/222 [05:51<01:32,  3.20s/it] 87%|████████▋ | 194/222 [05:52<01:09,  2.50s/it] 88%|████████▊ | 195/222 [05:53<00:54,  2.02s/it] 88%|████████▊ | 196/222 [05:54<00:43,  1.68s/it] 89%|████████▊ | 197/222 [05:55<00:36,  1.44s/it] 89%|████████▉ | 198/222 [05:56<00:30,  1.28s/it] 90%|████████▉ | 199/222 [05:57<00:27,  1.18s/it] 90%|█████████ | 200/222 [05:58<00:23,  1.08s/it] 91%|█████████ | 201/222 [06:05<01:02,  2.99s/it] 91%|█████████ | 202/222 [06:06<00:47,  2.37s/it] 91%|█████████▏| 203/222 [06:07<00:36,  1.90s/it] 92%|█████████▏| 204/222 [06:08<00:28,  1.57s/it] 92%|█████████▏| 205/222 [06:08<00:23,  1.35s/it] 93%|█████████▎| 206/222 [06:09<00:19,  1.24s/it] 93%|█████████▎| 207/222 [06:10<00:16,  1.12s/it] 94%|█████████▎| 208/222 [06:11<00:14,  1.04s/it] 94%|█████████▍| 209/222 [06:18<00:37,  2.91s/it] 95%|█████████▍| 210/222 [06:19<00:27,  2.26s/it] 95%|█████████▌| 211/222 [06:20<00:19,  1.82s/it] 95%|█████████▌| 212/222 [06:21<00:14,  1.49s/it] 96%|█████████▌| 213/222 [06:21<00:11,  1.28s/it] 96%|█████████▋| 214/222 [06:22<00:08,  1.12s/it] 97%|█████████▋| 215/222 [06:23<00:07,  1.00s/it] 97%|█████████▋| 216/222 [06:24<00:05,  1.07it/s] 98%|█████████▊| 217/222 [06:28<00:09,  1.81s/it] 98%|█████████▊| 218/222 [06:28<00:05,  1.43s/it] 99%|█████████▊| 219/222 [06:29<00:03,  1.17s/it] 99%|█████████▉| 220/222 [06:29<00:01,  1.02it/s]100%|█████████▉| 221/222 [06:30<00:00,  1.17it/s]100%|██████████| 222/222 [06:30<00:00,  1.57it/s]100%|██████████| 222/222 [06:30<00:00,  1.76s/it]
