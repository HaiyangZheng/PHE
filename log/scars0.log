2024-12-08 23:21:24,478 - main - INFO - Start running with args: 
Namespace(batch_size=128, img_size=224, prototype_shape=[2000, 192, 1, 1], prototype_activation_function='log', add_on_layers_type='regular', use_global=True, global_proto_per_class=10, epochs=200, save_ep_freq=10, hash_code_length=12, prototype_dim=768, alpha=0.1, beta=3.0, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', features_lr=0.0001, add_on_layers_lr=0.001, prototype_vectors_lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=0.0001, min_lr=1e-05, decay_epochs=10, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, prop_train_labels=0.5, mask_theta=0.1, labeled_nums=0, unlabeled_nums=0, data_set='scars', output_dir='exp//scars/scars_iscap_seed(1027)', device='cuda', seed=1027, resume='', start_epoch=0, eval=False, num_workers=10, pin_mem=True, data_root='/leonardo_work/IscrC_Fed-GCD/GCD_datasets/stanford_cars', pretrain_path='/leonardo_work/IscrC_Fed-GCD/GCD_datasets/dino/dino_vitbase16_pretrain.pth')
/leonardo/home/userexternal/hzheng00/miniconda3/envs/fedgcd/lib/python3.9/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2024-12-08 23:21:24,870 - main - INFO - train 2000 test: 3948
2024-12-08 23:21:24,871 - main - INFO - test_dataset_unlabelled: 6144
/leonardo/home/userexternal/hzheng00/miniconda3/envs/fedgcd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/leonardo/home/userexternal/hzheng00/miniconda3/envs/fedgcd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2024-12-08 23:21:28,624 - main - INFO - number of params: 14730520
2024-12-08 23:21:28,625 - main - INFO - Start training for 200 epochs
2024-12-08 23:21:28,626 - train_and_evaluate - INFO - Start train one epoch
train_classes: [1, 11, 25, 38, 46, 50, 53, 75, 84, 100, 105, 117, 123, 129, 133, 134, 135, 136, 137, 138, 140, 144, 145, 146, 147, 149, 150, 151, 153, 160, 161, 162, 163, 164, 167, 168, 169, 174, 175, 180, 185, 186, 187, 192, 193, 0, 81, 97, 104, 122, 139, 141, 142, 143, 148, 152, 154, 155, 156, 157, 158, 159, 165, 166, 170, 171, 172, 173, 176, 177, 181, 184, 188, 191, 194, 195, 2, 7, 9, 16, 20, 26, 28, 44, 54, 95, 98, 102, 127, 178, 182, 22, 41, 82, 93, 112, 125, 189]
len(train_classes): 98
unlabeled_classes: [23, 42, 83, 94, 113, 126, 190, 3, 8, 10, 17, 21, 27, 29, 45, 55, 96, 99, 103, 128, 179, 183, 4, 5, 6, 12, 13, 14, 15, 18, 19, 24, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 43, 47, 48, 49, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 85, 86, 87, 88, 89, 90, 91, 92, 101, 106, 107, 108, 109, 110, 111, 114, 115, 116, 118, 119, 120, 121, 124, 130, 131, 132]
len(unlabeled_classes): 98
require grad: prototype_vectors_global
require grad: features.blocks.11.norm1.weight
require grad: features.blocks.11.norm1.bias
require grad: features.blocks.11.attn.qkv.weight
require grad: features.blocks.11.attn.qkv.bias
require grad: features.blocks.11.attn.proj.weight
require grad: features.blocks.11.attn.proj.bias
require grad: features.blocks.11.norm2.weight
require grad: features.blocks.11.norm2.bias
require grad: features.blocks.11.mlp.fc1.weight
require grad: features.blocks.11.mlp.fc1.bias
require grad: features.blocks.11.mlp.fc2.weight
require grad: features.blocks.11.mlp.fc2.bias
require grad: add_on_layers.0.weight
require grad: add_on_layers.0.bias
require grad: hash_head.mlp.0.weight
require grad: hash_head.mlp.0.bias
require grad: hash_head.mlp.2.weight
require grad: hash_head.mlp.2.bias
require grad: hash_head.mlp.4.weight
require grad: hash_head.mlp.4.bias
require grad: hash_head.mlp.5.weight
require grad: hash_head.mlp.5.bias
require grad: hash_head.hash.weight
require grad: hash_head.bn_h.weight
require grad: hash_head.bn_h.bias
Param Group 0:
Parameters:
torch.Size([768])
torch.Size([768])
torch.Size([2304, 768])
torch.Size([2304])
torch.Size([768, 768])
torch.Size([768])
torch.Size([768])
torch.Size([768])
torch.Size([3072, 768])
torch.Size([3072])
torch.Size([768, 3072])
torch.Size([768])
Config:
lr: 0.0001
weight_decay: 0.001
betas: (0.9, 0.999)
eps: 1e-08
amsgrad: False
foreach: None
maximize: False
capturable: False


Param Group 1:
Parameters:
torch.Size([768, 768])
torch.Size([768])
Config:
lr: 0.001
weight_decay: 0.001
betas: (0.9, 0.999)
eps: 1e-08
amsgrad: False
foreach: None
maximize: False
capturable: False


Param Group 2:
Parameters:
torch.Size([2048, 768])
torch.Size([2048])
torch.Size([2048, 2048])
torch.Size([2048])
torch.Size([256, 2048])
torch.Size([256])
torch.Size([256])
torch.Size([256])
torch.Size([12, 256])
torch.Size([12])
torch.Size([12])
Config:
lr: 0.001
betas: (0.9, 0.999)
eps: 1e-08
weight_decay: 0.05
amsgrad: False
foreach: None
maximize: False
capturable: False


Param Group 3:
Parameters:
torch.Size([980, 768])
Config:
lr: 0.001
betas: (0.9, 0.999)
eps: 1e-08
weight_decay: 0.05
amsgrad: False
foreach: None
maximize: False
capturable: False


d_max: 3
2024-12-08 23:21:59,808 - log_every - INFO - Epoch: [0]  [ 0/16]  eta: 0:08:18  lr: 0.000100  loss_protop: 4.8824 (4.8824)  loss_feature: 4.5584 (4.5584)  loss_sep: 0.0000 (0.0000)  loss_quan: 0.5898 (0.5898)  time: 31.1822  data: 18.0458  max mem: 3395
2024-12-08 23:22:01,495 - log_every - INFO - Epoch: [0]  [15/16]  eta: 0:00:02  lr: 0.000100  loss_protop: 4.9097 (4.9255)  loss_feature: 4.2961 (4.3544)  loss_sep: 0.0000 (0.0227)  loss_quan: 0.4377 (0.4606)  time: 2.0542  data: 1.1279  max mem: 3567
2024-12-08 23:22:01,710 - log_every - INFO - Epoch: [0] Total time: 0:00:33 (2.0678 s / it)
2024-12-08 23:22:01,711 - evaluate - INFO - Start validation
2024-12-08 23:22:01,711 - evaluate - INFO - Radius: 1
Averaged stats: lr: 0.000100  loss_protop: 4.9097 (4.9255)  loss_feature: 4.2961 (4.3544)  loss_sep: 0.0000 (0.0227)  loss_quan: 0.4377 (0.4606)
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:25<09:43, 25.38s/it]  8%|▊         | 2/24 [00:26<04:02, 11.00s/it] 12%|█▎        | 3/24 [00:27<02:14,  6.41s/it] 17%|█▋        | 4/24 [00:28<01:24,  4.23s/it] 21%|██        | 5/24 [00:29<00:57,  3.02s/it] 25%|██▌       | 6/24 [00:29<00:41,  2.30s/it] 29%|██▉       | 7/24 [00:30<00:31,  1.85s/it] 33%|███▎      | 8/24 [00:31<00:24,  1.54s/it] 38%|███▊      | 9/24 [00:52<01:53,  7.54s/it] 42%|████▏     | 10/24 [00:53<01:16,  5.48s/it] 46%|████▌     | 11/24 [00:54<00:53,  4.10s/it] 50%|█████     | 12/24 [00:55<00:37,  3.12s/it] 54%|█████▍    | 13/24 [00:56<00:27,  2.46s/it] 58%|█████▊    | 14/24 [00:57<00:20,  2.00s/it] 62%|██████▎   | 15/24 [00:57<00:15,  1.67s/it] 67%|██████▋   | 16/24 [00:58<00:11,  1.44s/it] 71%|███████   | 17/24 [01:11<00:32,  4.66s/it] 75%|███████▌  | 18/24 [01:11<00:20,  3.42s/it] 79%|███████▉  | 19/24 [01:12<00:12,  2.56s/it] 83%|████████▎ | 20/24 [01:12<00:07,  1.96s/it] 88%|████████▊ | 21/24 [01:13<00:04,  1.54s/it] 92%|█████████▏| 22/24 [01:13<00:02,  1.24s/it] 96%|█████████▌| 23/24 [01:14<00:01,  1.04s/it]100%|██████████| 24/24 [01:14<00:00,  1.12it/s]100%|██████████| 24/24 [01:15<00:00,  3.14s/it]
2024-12-08 23:23:18,078 - evaluate - INFO - Evaluate V1: all_acc: 0.111 old_acc: 0.133 new_acc: 0.100
2024-12-08 23:23:18,086 - evaluate - INFO - Evaluate V2: all_acc: 0.082 old_acc: 0.066 new_acc: 0.090
2024-12-08 23:23:18,087 - main - INFO - Averaged stats:
2024-12-08 23:23:18,087 - main - INFO - {'lr': 0.00010000000000000003, 'loss_protop': 4.92552250623703, 'loss_feature': 4.354369163513184, 'loss_sep': 0.022737463576049777, 'loss_quan': 0.4606475830078125}
2024-12-08 23:23:18,088 - train_and_evaluate - INFO - Start train one epoch
d_max: 3
2024-12-08 23:23:33,678 - log_every - INFO - Epoch: [1]  [ 0/16]  eta: 0:04:09  lr: 0.000100  loss_protop: 5.0198 (5.0198)  loss_feature: 4.0661 (4.0661)  loss_sep: 0.1263 (0.1263)  loss_quan: 0.3506 (0.3506)  time: 15.5899  data: 15.3244  max mem: 3567
2024-12-08 23:23:45,022 - log_every - INFO - Epoch: [1]  [15/16]  eta: 0:00:01  lr: 0.000100  loss_protop: 4.8750 (4.8976)  loss_feature: 4.0047 (4.0088)  loss_sep: 0.0980 (0.0965)  loss_quan: 0.3416 (0.3418)  time: 1.6833  data: 1.5093  max mem: 3567
2024-12-08 23:23:45,482 - log_every - INFO - Epoch: [1] Total time: 0:00:27 (1.7121 s / it)
2024-12-08 23:23:45,483 - evaluate - INFO - Start validation
2024-12-08 23:23:45,483 - evaluate - INFO - Radius: 1
Averaged stats: lr: 0.000100  loss_protop: 4.8750 (4.8976)  loss_feature: 4.0047 (4.0088)  loss_sep: 0.0980 (0.0965)  loss_quan: 0.3416 (0.3418)
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:25<09:39, 25.17s/it]  8%|▊         | 2/24 [00:26<03:59, 10.90s/it] 12%|█▎        | 3/24 [00:26<02:12,  6.33s/it] 17%|█▋        | 4/24 [00:27<01:23,  4.20s/it] 21%|██        | 5/24 [00:28<00:57,  3.01s/it] 25%|██▌       | 6/24 [00:29<00:41,  2.30s/it] 29%|██▉       | 7/24 [00:30<00:31,  1.84s/it] 33%|███▎      | 8/24 [00:31<00:24,  1.54s/it] 38%|███▊      | 9/24 [00:52<01:52,  7.53s/it] 42%|████▏     | 10/24 [00:53<01:16,  5.48s/it] 46%|████▌     | 11/24 [00:54<00:53,  4.08s/it] 50%|█████     | 12/24 [00:54<00:37,  3.12s/it] 54%|█████▍    | 13/24 [00:55<00:26,  2.45s/it] 58%|█████▊    | 14/24 [00:56<00:19,  1.99s/it] 62%|██████▎   | 15/24 [00:57<00:15,  1.67s/it] 67%|██████▋   | 16/24 [00:58<00:11,  1.45s/it] 71%|███████   | 17/24 [01:09<00:29,  4.23s/it] 75%|███████▌  | 18/24 [01:09<00:18,  3.13s/it] 79%|███████▉  | 19/24 [01:10<00:11,  2.36s/it] 83%|████████▎ | 20/24 [01:11<00:07,  1.82s/it] 88%|████████▊ | 21/24 [01:11<00:04,  1.44s/it] 92%|█████████▏| 22/24 [01:12<00:02,  1.18s/it] 96%|█████████▌| 23/24 [01:12<00:00,  1.01it/s]100%|██████████| 24/24 [01:13<00:00,  1.16it/s]100%|██████████| 24/24 [01:13<00:00,  3.07s/it]
2024-12-08 23:25:00,326 - evaluate - INFO - Evaluate V1: all_acc: 0.118 old_acc: 0.144 new_acc: 0.105
2024-12-08 23:25:00,333 - evaluate - INFO - Evaluate V2: all_acc: 0.088 old_acc: 0.064 new_acc: 0.099
2024-12-08 23:25:00,334 - main - INFO - Averaged stats:
2024-12-08 23:25:00,335 - main - INFO - {'lr': 0.00010000000000000003, 'loss_protop': 4.897632211446762, 'loss_feature': 4.008787542581558, 'loss_sep': 0.09652522893156856, 'loss_quan': 0.341827392578125}
2024-12-08 23:25:00,335 - train_and_evaluate - INFO - Start train one epoch
d_max: 3
2024-12-08 23:25:17,101 - log_every - INFO - Epoch: [2]  [ 0/16]  eta: 0:04:28  lr: 0.000100  loss_protop: 4.8777 (4.8777)  loss_feature: 3.9443 (3.9443)  loss_sep: 0.0220 (0.0220)  loss_quan: 0.3435 (0.3435)  time: 16.7647  data: 16.5049  max mem: 3567
2024-12-08 23:25:27,378 - log_every - INFO - Epoch: [2]  [15/16]  eta: 0:00:01  lr: 0.000100  loss_protop: 4.8777 (4.8877)  loss_feature: 3.9049 (3.9073)  loss_sep: 0.0411 (0.0473)  loss_quan: 0.3384 (0.3375)  time: 1.6899  data: 1.5169  max mem: 3567
2024-12-08 23:25:27,834 - log_every - INFO - Epoch: [2] Total time: 0:00:27 (1.7186 s / it)
2024-12-08 23:25:27,834 - evaluate - INFO - Start validation
2024-12-08 23:25:27,834 - evaluate - INFO - Radius: 1
Averaged stats: lr: 0.000100  loss_protop: 4.8777 (4.8877)  loss_feature: 3.9049 (3.9073)  loss_sep: 0.0411 (0.0473)  loss_quan: 0.3384 (0.3375)
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:25<09:37, 25.12s/it]  8%|▊         | 2/24 [00:26<03:59, 10.87s/it] 12%|█▎        | 3/24 [00:26<02:13,  6.33s/it] 17%|█▋        | 4/24 [00:27<01:24,  4.21s/it] 21%|██        | 5/24 [00:28<00:57,  3.02s/it] 25%|██▌       | 6/24 [00:29<00:41,  2.31s/it] 29%|██▉       | 7/24 [00:30<00:31,  1.86s/it] 33%|███▎      | 8/24 [00:31<00:24,  1.56s/it] 38%|███▊      | 9/24 [00:52<01:52,  7.53s/it] 42%|████▏     | 10/24 [00:53<01:17,  5.51s/it] 46%|████▌     | 11/24 [00:54<00:53,  4.11s/it] 50%|█████     | 12/24 [00:55<00:37,  3.13s/it] 54%|█████▍    | 13/24 [00:55<00:27,  2.46s/it] 58%|█████▊    | 14/24 [00:56<00:20,  2.01s/it] 62%|██████▎   | 15/24 [00:57<00:15,  1.69s/it] 67%|██████▋   | 16/24 [00:58<00:11,  1.47s/it] 71%|███████   | 17/24 [01:09<00:29,  4.20s/it] 75%|███████▌  | 18/24 [01:09<00:18,  3.11s/it] 79%|███████▉  | 19/24 [01:10<00:11,  2.34s/it] 83%|████████▎ | 20/24 [01:11<00:07,  1.81s/it] 88%|████████▊ | 21/24 [01:11<00:04,  1.43s/it] 92%|█████████▏| 22/24 [01:12<00:02,  1.17s/it] 96%|█████████▌| 23/24 [01:12<00:00,  1.01it/s]100%|██████████| 24/24 [01:13<00:00,  1.17it/s]100%|██████████| 24/24 [01:13<00:00,  3.07s/it]
2024-12-08 23:26:42,859 - evaluate - INFO - Evaluate V1: all_acc: 0.138 old_acc: 0.167 new_acc: 0.123
2024-12-08 23:26:42,867 - evaluate - INFO - Evaluate V2: all_acc: 0.105 old_acc: 0.086 new_acc: 0.114
2024-12-08 23:26:42,869 - main - INFO - Averaged stats:
2024-12-08 23:26:42,869 - main - INFO - {'lr': 0.00010000000000000003, 'loss_protop': 4.887660562992096, 'loss_feature': 3.9072730988264084, 'loss_sep': 0.04732092935591936, 'loss_quan': 0.3375396728515625}
2024-12-08 23:26:42,870 - train_and_evaluate - INFO - Start train one epoch
d_max: 3
